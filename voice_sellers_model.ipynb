{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install sqlite3\n",
        "!pip install pyaudio\n",
        "!pip install langchain\n",
        "!pip install langchain_community\n",
        "!pip install openai\n",
        "!pip install langchain_experimental\n",
        "!pip install pydub\n",
        "!pip install simpleaudio\n",
        "!pip install sounddevice\n",
        "!pip install soundfile"
      ],
      "metadata": {
        "id": "phkDMlmLxVXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyaudio\n",
        "import numpy as np\n",
        "import time\n",
        "import wave\n",
        "from threading import Thread\n",
        "import os\n",
        "import sqlite3\n",
        "from langchain import SQLDatabase\n",
        "from langchain_experimental.sql import SQLDatabaseChain\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from pydub import AudioSegment\n",
        "from pydub.playback import play\n",
        "from openai import OpenAI as OpenAIApi\n",
        "from IPython.display import Audio\n",
        "from io import BytesIO\n",
        "from langchain import OpenAI as LangchainOpenAI"
      ],
      "metadata": {
        "id": "VbYMd-1xxZFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "CHUNK = 1024\n",
        "FORMAT = pyaudio.paInt16\n",
        "CHANNELS = 1\n",
        "RATE = 44100\n",
        "SILENCE_THRESHOLD = 500  # Threshold for detecting silence\n",
        "SILENCE_DURATION = 2  # Duration to wait for silence in seconds\n",
        "\n",
        "class AudioRecorder(Thread):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.recording = True\n",
        "        self.audio_data = []\n",
        "\n",
        "    def run(self):\n",
        "        p = pyaudio.PyAudio()\n",
        "        stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE,\n",
        "                        input=True, frames_per_buffer=CHUNK)\n",
        "\n",
        "        print(\"Recording...\")\n",
        "\n",
        "        start_time = time.time()\n",
        "        while self.recording:\n",
        "            data = stream.read(CHUNK)\n",
        "            self.audio_data.append(data)\n",
        "            audio_np = np.frombuffer(data, dtype=np.int16)\n",
        "            if np.max(np.abs(audio_np)) < SILENCE_THRESHOLD:\n",
        "                if time.time() - start_time > SILENCE_DURATION:\n",
        "                    self.recording = False\n",
        "            else:\n",
        "                start_time = time.time()\n",
        "\n",
        "        stream.stop_stream()\n",
        "        stream.close()\n",
        "        p.terminate()\n",
        "        print(\"Recording stopped.\")\n",
        "\n",
        "# Start recording\n",
        "recorder = AudioRecorder()\n",
        "recorder.start()\n",
        "\n",
        "# Wait for recording to finish\n",
        "recorder.join()\n",
        "\n",
        "# Save the audio data to a WAV file\n",
        "with wave.open('output1.wav', 'wb') as wf:\n",
        "    wf.setnchannels(CHANNELS)\n",
        "    wf.setsampwidth(pyaudio.PyAudio().get_sample_size(FORMAT))\n",
        "    wf.setframerate(RATE)\n",
        "    wf.writeframes(b''.join(recorder.audio_data))\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = your_open_api_key\n",
        "\n",
        "############################################################\n",
        "client = OpenAIApi()\n",
        "audio_file= open(\"/content/a.wav\", \"rb\")\n",
        "transcription = client.audio.translations.create(\n",
        "  model=\"whisper-1\",\n",
        "  file=audio_file\n",
        ")\n",
        "input = transcription.text\n",
        "\n",
        "###############################################################\n",
        "prompt = f\"\"\"\n",
        " You are a friendly and knowledgeable sales assistant specializing in fashion.\n",
        " give the output in the human english like a real person.\n",
        " Respond naturally and conversationally, as if you were a real person.\n",
        " Provide personalized clothing recommendations, focusing on style and fit.\n",
        " Keep your answers short, sweet, and helpful, without unnecessary details like(product ids ), if the coustmer were asking the give it.\n",
        "\n",
        "\n",
        " Customer: {input}\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "# Initialize the OpenAI model\n",
        "openai_llm = LangchainOpenAI()\n",
        "\n",
        "# Initialize memory to keep track of chat history\n",
        "memory = ConversationBufferMemory()\n",
        "\n",
        "# Initialize the SQL database connection\n",
        "input_db = SQLDatabase.from_uri(\"sqlite:///your_database.db\")\n",
        "\n",
        "# Use the LLM instance in the SQLDatabaseChain\n",
        "db_chain = SQLDatabaseChain.from_llm(llm=openai_llm, db=input_db, verbose=False)\n",
        "\n",
        "def get_response(user_input):\n",
        "    # Combine the system prompt with the current chat history\n",
        "    full_prompt = f\"{prompt}\\n{memory.chat_memory.messages}\\nCustomer: {user_input}\"\n",
        "\n",
        "    # Run the SQLDatabaseChain with the given prompt\n",
        "    response = db_chain.run(full_prompt)\n",
        "\n",
        "    # Update memory with the latest interaction\n",
        "    memory.chat_memory.add_message(f\"Customer: {user_input}\")  # Combine sender and message into a single string\n",
        "    memory.chat_memory.add_message(f\"Seller: {response}\")  # Combine sender and message into a single string\n",
        "\n",
        "    return response\n",
        "\n",
        "####################################################################\n",
        "\n",
        "text = get_response(input)\n",
        "\n",
        "response = client.audio.speech.create(\n",
        "          model=\"tts-1-hd\",\n",
        "          voice=\"alloy\",\n",
        "          input= text,\n",
        "      )\n",
        "audio_data = response.content  # Convert response to a file-like object\n",
        "\n",
        "# Use IPython.display.Audio to play the audio in Jupyter/Colab\n",
        "Audio(data=audio_data, autoplay=True)"
      ],
      "metadata": {
        "id": "uK81aNenuXtz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}